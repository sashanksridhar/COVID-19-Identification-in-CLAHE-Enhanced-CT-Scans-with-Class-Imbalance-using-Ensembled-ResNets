{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Resnet.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1dtMMJ-EUR2EeVupHDejDZJvSxN6qpR89","authorship_tag":"ABX9TyNq36BlnzvdfZ3Kl9Rr6vpd"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s3EGfn21xuZ5","executionInfo":{"status":"ok","timestamp":1611417065804,"user_tz":-330,"elapsed":56114,"user":{"displayName":"covid project","photoUrl":"","userId":"04822791065494456352"}},"outputId":"b5c4946a-f53d-4001-a852-6ff1c1e95a8b"},"source":["!pip install tensorflow-gpu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/6d/67169e8d8146f377bbfd71d6c108a0fce218411371ce41d440a7a5f5fb20/tensorflow_gpu-2.4.1-cp36-cp36m-manylinux2010_x86_64.whl (394.3MB)\n","\u001b[K     |████████████████████████████████| 394.3MB 44kB/s \n","\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.0)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.36.2)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.4.0)\n","Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n","Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.19.5)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.7.4.3)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.17.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (51.3.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.7.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.3)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.0)\n","Installing collected packages: tensorflow-gpu\n","Successfully installed tensorflow-gpu-2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"id":"npUwskDzxZd0","executionInfo":{"status":"error","timestamp":1611417068007,"user_tz":-330,"elapsed":47923,"user":{"displayName":"covid project","photoUrl":"","userId":"04822791065494456352"}},"outputId":"f36b00e2-28c0-4b7e-e7f8-795bab127272"},"source":["from __future__ import print_function\r\n","import keras\r\n","from keras.layers import Dense, Conv2D, BatchNormalization, Activation\r\n","from keras.layers import AveragePooling2D, Input, Flatten\r\n","from keras.optimizers import Adam\r\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n","from keras.callbacks import ReduceLROnPlateau\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.regularizers import l2\r\n","from keras import backend as K\r\n","from keras.models import Model\r\n","import numpy as np\r\n","import os\r\n","from keras.utils import plot_model\r\n","# Training parameters\r\n","batch_size = 32  # orig paper trained all networks with batch_size=128\r\n","epochs = 200\r\n","num_classes = 2\r\n","\r\n","# Subtracting pixel mean improves accuracy\r\n","subtract_pixel_mean = True\r\n","\r\n","# Model parameter\r\n","# ----------------------------------------------------------------------------\r\n","#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\r\n","# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\r\n","#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\r\n","# ----------------------------------------------------------------------------\r\n","# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\r\n","# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\r\n","# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\r\n","# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\r\n","# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\r\n","# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\r\n","# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\r\n","# ---------------------------------------------------------------------------\r\n","n = 3\r\n","\r\n","# Model version\r\n","# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\r\n","version = 1\r\n","\r\n","# Computed depth from supplied model parameter n\r\n","if version == 1:\r\n","    depth = n * 6 + 2\r\n","elif version == 2:\r\n","    depth = n * 9 + 2\r\n","\r\n","# Model name, depth and version\r\n","model_type = 'ResNet%dv%d' % (depth, version)\r\n","\r\n","# Input image dimensions.\r\n","\r\n","\r\n","def lr_schedule(epoch):\r\n","    \"\"\"Learning Rate Schedule\r\n","\r\n","    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\r\n","    Called automatically every epoch as part of callbacks during training.\r\n","\r\n","    # Arguments\r\n","        epoch (int): The number of epochs\r\n","\r\n","    # Returns\r\n","        lr (float32): learning rate\r\n","    \"\"\"\r\n","    lr = 1e-3\r\n","    if epoch > 180:\r\n","        lr *= 0.5e-3\r\n","    elif epoch > 160:\r\n","        lr *= 1e-3\r\n","    elif epoch > 120:\r\n","        lr *= 1e-2\r\n","    elif epoch > 80:\r\n","        lr *= 1e-1\r\n","    print('Learning rate: ', lr)\r\n","    return lr\r\n","\r\n","\r\n","def resnet_layer(inputs,\r\n","                 num_filters=16,\r\n","                 kernel_size=3,\r\n","                 strides=1,\r\n","                 activation='relu',\r\n","                 batch_normalization=True,\r\n","                 conv_first=True):\r\n","    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\r\n","\r\n","    # Arguments\r\n","        inputs (tensor): input tensor from input image or previous layer\r\n","        num_filters (int): Conv2D number of filters\r\n","        kernel_size (int): Conv2D square kernel dimensions\r\n","        strides (int): Conv2D square stride dimensions\r\n","        activation (string): activation name\r\n","        batch_normalization (bool): whether to include batch normalization\r\n","        conv_first (bool): conv-bn-activation (True) or\r\n","            bn-activation-conv (False)\r\n","\r\n","    # Returns\r\n","        x (tensor): tensor as input to the next layer\r\n","    \"\"\"\r\n","    conv = Conv2D(num_filters,\r\n","                  kernel_size=kernel_size,\r\n","                  strides=strides,\r\n","                  padding='same',\r\n","                  kernel_initializer='he_normal',\r\n","                  kernel_regularizer=l2(1e-4))\r\n","\r\n","    x = inputs\r\n","    if conv_first:\r\n","        x = conv(x)\r\n","        if batch_normalization:\r\n","            x = BatchNormalization()(x)\r\n","        if activation is not None:\r\n","            x = Activation(activation)(x)\r\n","    else:\r\n","        if batch_normalization:\r\n","            x = BatchNormalization()(x)\r\n","        if activation is not None:\r\n","            x = Activation(activation)(x)\r\n","        x = conv(x)\r\n","    return x\r\n","\r\n","\r\n","def resnet_v1(input_shape, depth, num_classes=2):\r\n","    \"\"\"ResNet Version 1 Model builder [a]\r\n","\r\n","    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\r\n","    Last ReLU is after the shortcut connection.\r\n","    At the beginning of each stage, the feature map size is halved (downsampled)\r\n","    by a convolutional layer with strides=2, while the number of filters is\r\n","    doubled. Within each stage, the layers have the same number filters and the\r\n","    same number of filters.\r\n","    Features maps sizes:\r\n","    stage 0: 32x32, 16\r\n","    stage 1: 16x16, 32\r\n","    stage 2:  8x8,  64\r\n","    The Number of parameters is approx the same as Table 6 of [a]:\r\n","    ResNet20 0.27M\r\n","    ResNet32 0.46M\r\n","    ResNet44 0.66M\r\n","    ResNet56 0.85M\r\n","    ResNet110 1.7M\r\n","\r\n","    # Arguments\r\n","        input_shape (tensor): shape of input image tensor\r\n","        depth (int): number of core convolutional layers\r\n","        num_classes (int): number of classes (CIFAR10 has 10)\r\n","\r\n","    # Returns\r\n","        model (Model): keras model instance\r\n","    \"\"\"\r\n","    if (depth - 2) % 6 != 0:\r\n","        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\r\n","    # Start model definition.\r\n","    num_filters = 16\r\n","    num_res_blocks = int((depth - 2) / 6)\r\n","\r\n","    inputs = Input(shape=input_shape)\r\n","    x = resnet_layer(inputs=inputs)\r\n","    # Instantiate the stack of residual units\r\n","    for stack in range(3):\r\n","        for res_block in range(num_res_blocks):\r\n","            strides = 1\r\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n","                strides = 2  # downsample\r\n","            y = resnet_layer(inputs=x,\r\n","                             num_filters=num_filters,\r\n","                             strides=strides)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters,\r\n","                             activation=None)\r\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n","                # linear projection residual shortcut connection to match\r\n","                # changed dims\r\n","                x = resnet_layer(inputs=x,\r\n","                                 num_filters=num_filters,\r\n","                                 kernel_size=1,\r\n","                                 strides=strides,\r\n","                                 activation=None,\r\n","                                 batch_normalization=False)\r\n","            x = keras.layers.add([x, y])\r\n","            x = Activation('relu')(x)\r\n","        num_filters *= 2\r\n","\r\n","    # Add classifier on top.\r\n","    # v1 does not use BN after last shortcut connection-ReLU\r\n","    x = AveragePooling2D(pool_size=8)(x)\r\n","    y = Flatten()(x)\r\n","    outputs = Dense(num_classes,\r\n","                    activation='softmax',\r\n","                    kernel_initializer='he_normal')(y)\r\n","\r\n","    # Instantiate model.\r\n","    model = Model(inputs=inputs, outputs=outputs)\r\n","    return model\r\n","\r\n","\r\n","def resnet_v2(input_shape, depth, num_classes=2):\r\n","    \"\"\"ResNet Version 2 Model builder [b]\r\n","\r\n","    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\r\n","    bottleneck layer\r\n","    First shortcut connection per layer is 1 x 1 Conv2D.\r\n","    Second and onwards shortcut connection is identity.\r\n","    At the beginning of each stage, the feature map size is halved (downsampled)\r\n","    by a convolutional layer with strides=2, while the number of filter maps is\r\n","    doubled. Within each stage, the layers have the same number filters and the\r\n","    same filter map sizes.\r\n","    Features maps sizes:\r\n","    conv1  : 32x32,  16\r\n","    stage 0: 32x32,  64\r\n","    stage 1: 16x16, 128\r\n","    stage 2:  8x8,  256\r\n","\r\n","    # Arguments\r\n","        input_shape (tensor): shape of input image tensor\r\n","        depth (int): number of core convolutional layers\r\n","        num_classes (int): number of classes (CIFAR10 has 10)\r\n","\r\n","    # Returns\r\n","        model (Model): keras model instance\r\n","    \"\"\"\r\n","    if (depth - 2) % 9 != 0:\r\n","        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\r\n","    # Start model definition.\r\n","    num_filters_in = 16\r\n","    num_res_blocks = int((depth - 2) / 9)\r\n","\r\n","    inputs = Input(shape=input_shape)\r\n","    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\r\n","    x = resnet_layer(inputs=inputs,\r\n","                     num_filters=num_filters_in,\r\n","                     conv_first=True)\r\n","\r\n","    # Instantiate the stack of residual units\r\n","    for stage in range(3):\r\n","        for res_block in range(num_res_blocks):\r\n","            activation = 'relu'\r\n","            batch_normalization = True\r\n","            strides = 1\r\n","            if stage == 0:\r\n","                num_filters_out = num_filters_in * 4\r\n","                if res_block == 0:  # first layer and first stage\r\n","                    activation = None\r\n","                    batch_normalization = False\r\n","            else:\r\n","                num_filters_out = num_filters_in * 2\r\n","                if res_block == 0:  # first layer but not first stage\r\n","                    strides = 2    # downsample\r\n","\r\n","            # bottleneck residual unit\r\n","            y = resnet_layer(inputs=x,\r\n","                             num_filters=num_filters_in,\r\n","                             kernel_size=1,\r\n","                             strides=strides,\r\n","                             activation=activation,\r\n","                             batch_normalization=batch_normalization,\r\n","                             conv_first=False)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters_in,\r\n","                             conv_first=False)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters_out,\r\n","                             kernel_size=1,\r\n","                             conv_first=False)\r\n","            if res_block == 0:\r\n","                # linear projection residual shortcut connection to match\r\n","                # changed dims\r\n","                x = resnet_layer(inputs=x,\r\n","                                 num_filters=num_filters_out,\r\n","                                 kernel_size=1,\r\n","                                 strides=strides,\r\n","                                 activation=None,\r\n","                                 batch_normalization=False)\r\n","            x = keras.layers.add([x, y])\r\n","\r\n","        num_filters_in = num_filters_out\r\n","\r\n","    # Add classifier on top.\r\n","    # v2 has BN-ReLU before Pooling\r\n","    x = BatchNormalization()(x)\r\n","    x = Activation('relu')(x)\r\n","    x = AveragePooling2D(pool_size=8)(x)\r\n","    y = Flatten()(x)\r\n","    outputs = Dense(num_classes,\r\n","                    activation='softmax',\r\n","                    kernel_initializer='he_normal')(y)\r\n","\r\n","    # Instantiate model.\r\n","    model = Model(inputs=inputs, outputs=outputs)\r\n","    return model\r\n","\r\n","\r\n","if version == 2:\r\n","    model = resnet_v2(input_shape=(256,256,3), depth=depth,num_classes=2)\r\n","else:\r\n","    model = resnet_v1(input_shape=(256,256,3), depth=depth,num_classes=2)\r\n","\r\n","model.compile(loss='categorical_crossentropy',\r\n","              optimizer=Adam(lr=0.01),\r\n","              metrics=['accuracy'])\r\n","model.summary()\r\n","print(model_type)\r\n","\r\n","plot_model(model, show_shapes=True, to_file='/content/drive/My Drive/model_graph.png')\r\n","\r\n","# Prepare model model saving directory.\r\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\r\n","model_name = 'covid19_%s_model.{epoch:03d}.h5' % model_type\r\n","if not os.path.isdir(save_dir):\r\n","    os.makedirs(save_dir)\r\n","filepath = os.path.join(save_dir, model_name)\r\n","\r\n","# Prepare callbacks for model saving and for learning rate adjustment.\r\n","checkpoint = ModelCheckpoint(filepath=filepath,\r\n","                             monitor='val_acc',\r\n","                             verbose=1,\r\n","                             save_best_only=True)\r\n","\r\n","lr_scheduler = LearningRateScheduler(lr_schedule)\r\n","\r\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n","                               cooldown=0,\r\n","                               patience=5,\r\n","                               min_lr=0.5e-6)\r\n","\r\n","callbacks = [checkpoint, lr_reducer, lr_scheduler]\r\n","\r\n","# Run training, with or without data augmentation.\r\n","\r\n","# This will do preprocessing and realtime data augmentation:\r\n","datagen = ImageDataGenerator(\r\n","    rotation_range=40,\r\n","        width_shift_range=0.2,\r\n","        height_shift_range=0.2,\r\n","        rescale=1./255,\r\n","        shear_range=0.2,\r\n","        zoom_range=0.2,\r\n","        horizontal_flip=True,\r\n","        fill_mode='nearest'\r\n","    )\r\n","\r\n","# Compute quantities required for featurewise normalization\r\n","# (std, mean, and principal components if ZCA whitening is applied).\r\n","train_generator=datagen.flow_from_directory(directory='/content/drive/MyDrive/clahe_covid',batch_size=64)\r\n","\r\n","# Fit the model on the batches generated by datagen.flow().\r\n","history = model.fit_generator(train_generator,\r\n","                    epochs=3,\r\n","                    callbacks=callbacks)\r\n","model.save(\"/content/drive/My Drive/covid19Resnet.h5\")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-b044ff75693f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m model.compile(loss='categorical_crossentropy',\n","\u001b[0;32m<ipython-input-2-b044ff75693f>\u001b[0m in \u001b[0;36mresnet_v1\u001b[0;34m(input_shape, depth, num_classes)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mnum_res_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;31m# Instantiate the stack of residual units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m     input_layer_config.update(\n\u001b[1;32m    308\u001b[0m         {'batch_size': batch_size, 'input_shape': shape})\n\u001b[0;32m--> 309\u001b[0;31m   \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_layer_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m   \u001b[0;31m# Return tensor including `_keras_history`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# Create an input node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mnode_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Store type spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/node.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layer, call_args, call_kwargs, outputs)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m# insufficient), but individual values might not support copy.copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# or be too expensive to deep copy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcall_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mcall_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[1;32m    659\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       expand_composites=expand_composites)\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m   \"\"\"\n\u001b[0;32m--> 579\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    540\u001b[0m           \u001b[0;34m\"flat_sequence had %d elements.  Structure: %s, flat_sequence: %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m           (len(flat_structure), len(flat_sequence), structure, flat_sequence))\n\u001b[0;32m--> 542\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msequence_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_sequence_like\u001b[0;34m(instance, args)\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0minstance_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m   \u001b[0;32melif\u001b[0m \u001b[0m_is_composite_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_spec\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;31m# Fall back to the subclass check.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasscheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0msubclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtype\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Check if it's a subclass of a subclass (recursive)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mscls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasses__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Check if it's a subclass of a subclass (recursive)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mscls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasses__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Check if it's a subclass of a subclass (recursive)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mscls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__subclasses__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/abc.py\u001b[0m in \u001b[0;36m__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;31m# Check if it's a subclass of a registered class (recursive)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mrcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abc_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/_weakrefset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_IterationGuard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitemref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitemref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"70YcO7jXvTeU","executionInfo":{"status":"error","timestamp":1611423371136,"user_tz":-330,"elapsed":3404817,"user":{"displayName":"covid project","photoUrl":"","userId":"04822791065494456352"}},"outputId":"bcf53b41-cd01-4569-e5f1-1647ab5b85d4"},"source":["from __future__ import print_function\r\n","import keras\r\n","from keras.layers import Dense, Conv2D, BatchNormalization, Activation\r\n","from keras.layers import AveragePooling2D, Input, Flatten\r\n","from keras.optimizers import Adam\r\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n","from keras.callbacks import ReduceLROnPlateau\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.regularizers import l2\r\n","from keras import backend as K\r\n","from keras.models import Model\r\n","import numpy as np\r\n","import os\r\n","from keras.utils import plot_model\r\n","# Training parameters\r\n","batch_size = 32  # orig paper trained all networks with batch_size=128\r\n","epochs = 200\r\n","num_classes = 2\r\n","\r\n","# Subtracting pixel mean improves accuracy\r\n","subtract_pixel_mean = True\r\n","\r\n","# Model parameter\r\n","# ----------------------------------------------------------------------------\r\n","#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\r\n","# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\r\n","#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\r\n","# ----------------------------------------------------------------------------\r\n","# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\r\n","# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\r\n","# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\r\n","# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\r\n","# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\r\n","# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\r\n","# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\r\n","# ---------------------------------------------------------------------------\r\n","n = 3\r\n","\r\n","# Model version\r\n","# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\r\n","version = 1\r\n","\r\n","# Computed depth from supplied model parameter n\r\n","if version == 1:\r\n","    depth = n * 6 + 2\r\n","elif version == 2:\r\n","    depth = n * 9 + 2\r\n","\r\n","# Model name, depth and version\r\n","model_type = 'ResNet%dv%d' % (depth, version)\r\n","\r\n","# Input image dimensions.\r\n","\r\n","\r\n","def lr_schedule(epoch):\r\n","    \"\"\"Learning Rate Schedule\r\n","\r\n","    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\r\n","    Called automatically every epoch as part of callbacks during training.\r\n","\r\n","    # Arguments\r\n","        epoch (int): The number of epochs\r\n","\r\n","    # Returns\r\n","        lr (float32): learning rate\r\n","    \"\"\"\r\n","    lr = 1e-3\r\n","    if epoch > 180:\r\n","        lr *= 0.5e-3\r\n","    elif epoch > 160:\r\n","        lr *= 1e-3\r\n","    elif epoch > 120:\r\n","        lr *= 1e-2\r\n","    elif epoch > 80:\r\n","        lr *= 1e-1\r\n","    print('Learning rate: ', lr)\r\n","    return lr\r\n","\r\n","\r\n","def resnet_layer(inputs,\r\n","                 num_filters=16,\r\n","                 kernel_size=3,\r\n","                 strides=1,\r\n","                 activation='relu',\r\n","                 batch_normalization=True,\r\n","                 conv_first=True):\r\n","    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\r\n","\r\n","    # Arguments\r\n","        inputs (tensor): input tensor from input image or previous layer\r\n","        num_filters (int): Conv2D number of filters\r\n","        kernel_size (int): Conv2D square kernel dimensions\r\n","        strides (int): Conv2D square stride dimensions\r\n","        activation (string): activation name\r\n","        batch_normalization (bool): whether to include batch normalization\r\n","        conv_first (bool): conv-bn-activation (True) or\r\n","            bn-activation-conv (False)\r\n","\r\n","    # Returns\r\n","        x (tensor): tensor as input to the next layer\r\n","    \"\"\"\r\n","    conv = Conv2D(num_filters,\r\n","                  kernel_size=kernel_size,\r\n","                  strides=strides,\r\n","                  padding='same',\r\n","                  kernel_initializer='he_normal',\r\n","                  kernel_regularizer=l2(1e-4))\r\n","\r\n","    x = inputs\r\n","    if conv_first:\r\n","        x = conv(x)\r\n","        if batch_normalization:\r\n","            x = BatchNormalization()(x)\r\n","        if activation is not None:\r\n","            x = Activation(activation)(x)\r\n","    else:\r\n","        if batch_normalization:\r\n","            x = BatchNormalization()(x)\r\n","        if activation is not None:\r\n","            x = Activation(activation)(x)\r\n","        x = conv(x)\r\n","    return x\r\n","\r\n","\r\n","def resnet_v1(input_shape, depth, num_classes=2):\r\n","    \"\"\"ResNet Version 1 Model builder [a]\r\n","\r\n","    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\r\n","    Last ReLU is after the shortcut connection.\r\n","    At the beginning of each stage, the feature map size is halved (downsampled)\r\n","    by a convolutional layer with strides=2, while the number of filters is\r\n","    doubled. Within each stage, the layers have the same number filters and the\r\n","    same number of filters.\r\n","    Features maps sizes:\r\n","    stage 0: 32x32, 16\r\n","    stage 1: 16x16, 32\r\n","    stage 2:  8x8,  64\r\n","    The Number of parameters is approx the same as Table 6 of [a]:\r\n","    ResNet20 0.27M\r\n","    ResNet32 0.46M\r\n","    ResNet44 0.66M\r\n","    ResNet56 0.85M\r\n","    ResNet110 1.7M\r\n","\r\n","    # Arguments\r\n","        input_shape (tensor): shape of input image tensor\r\n","        depth (int): number of core convolutional layers\r\n","        num_classes (int): number of classes (CIFAR10 has 10)\r\n","\r\n","    # Returns\r\n","        model (Model): keras model instance\r\n","    \"\"\"\r\n","    if (depth - 2) % 6 != 0:\r\n","        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\r\n","    # Start model definition.\r\n","    num_filters = 16\r\n","    num_res_blocks = int((depth - 2) / 6)\r\n","\r\n","    inputs = Input(shape=input_shape)\r\n","    x = resnet_layer(inputs=inputs)\r\n","    # Instantiate the stack of residual units\r\n","    for stack in range(3):\r\n","        for res_block in range(num_res_blocks):\r\n","            strides = 1\r\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n","                strides = 2  # downsample\r\n","            y = resnet_layer(inputs=x,\r\n","                             num_filters=num_filters,\r\n","                             strides=strides)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters,\r\n","                             activation=None)\r\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n","                # linear projection residual shortcut connection to match\r\n","                # changed dims\r\n","                x = resnet_layer(inputs=x,\r\n","                                 num_filters=num_filters,\r\n","                                 kernel_size=1,\r\n","                                 strides=strides,\r\n","                                 activation=None,\r\n","                                 batch_normalization=False)\r\n","            x = keras.layers.add([x, y])\r\n","            x = Activation('relu')(x)\r\n","        num_filters *= 2\r\n","\r\n","    # Add classifier on top.\r\n","    # v1 does not use BN after last shortcut connection-ReLU\r\n","    x = AveragePooling2D(pool_size=8)(x)\r\n","    y = Flatten()(x)\r\n","    outputs = Dense(num_classes,\r\n","                    activation='softmax',\r\n","                    kernel_initializer='he_normal')(y)\r\n","\r\n","    # Instantiate model.\r\n","    model = Model(inputs=inputs, outputs=outputs)\r\n","    return model\r\n","\r\n","\r\n","def resnet_v2(input_shape, depth, num_classes=2):\r\n","    \"\"\"ResNet Version 2 Model builder [b]\r\n","\r\n","    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\r\n","    bottleneck layer\r\n","    First shortcut connection per layer is 1 x 1 Conv2D.\r\n","    Second and onwards shortcut connection is identity.\r\n","    At the beginning of each stage, the feature map size is halved (downsampled)\r\n","    by a convolutional layer with strides=2, while the number of filter maps is\r\n","    doubled. Within each stage, the layers have the same number filters and the\r\n","    same filter map sizes.\r\n","    Features maps sizes:\r\n","    conv1  : 32x32,  16\r\n","    stage 0: 32x32,  64\r\n","    stage 1: 16x16, 128\r\n","    stage 2:  8x8,  256\r\n","\r\n","    # Arguments\r\n","        input_shape (tensor): shape of input image tensor\r\n","        depth (int): number of core convolutional layers\r\n","        num_classes (int): number of classes (CIFAR10 has 10)\r\n","\r\n","    # Returns\r\n","        model (Model): keras model instance\r\n","    \"\"\"\r\n","    if (depth - 2) % 9 != 0:\r\n","        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\r\n","    # Start model definition.\r\n","    num_filters_in = 16\r\n","    num_res_blocks = int((depth - 2) / 9)\r\n","\r\n","    inputs = Input(shape=input_shape)\r\n","    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\r\n","    x = resnet_layer(inputs=inputs,\r\n","                     num_filters=num_filters_in,\r\n","                     conv_first=True)\r\n","\r\n","    # Instantiate the stack of residual units\r\n","    for stage in range(3):\r\n","        for res_block in range(num_res_blocks):\r\n","            activation = 'relu'\r\n","            batch_normalization = True\r\n","            strides = 1\r\n","            if stage == 0:\r\n","                num_filters_out = num_filters_in * 4\r\n","                if res_block == 0:  # first layer and first stage\r\n","                    activation = None\r\n","                    batch_normalization = False\r\n","            else:\r\n","                num_filters_out = num_filters_in * 2\r\n","                if res_block == 0:  # first layer but not first stage\r\n","                    strides = 2    # downsample\r\n","\r\n","            # bottleneck residual unit\r\n","            y = resnet_layer(inputs=x,\r\n","                             num_filters=num_filters_in,\r\n","                             kernel_size=1,\r\n","                             strides=strides,\r\n","                             activation=activation,\r\n","                             batch_normalization=batch_normalization,\r\n","                             conv_first=False)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters_in,\r\n","                             conv_first=False)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters_out,\r\n","                             kernel_size=1,\r\n","                             conv_first=False)\r\n","            if res_block == 0:\r\n","                # linear projection residual shortcut connection to match\r\n","                # changed dims\r\n","                x = resnet_layer(inputs=x,\r\n","                                 num_filters=num_filters_out,\r\n","                                 kernel_size=1,\r\n","                                 strides=strides,\r\n","                                 activation=None,\r\n","                                 batch_normalization=False)\r\n","            x = keras.layers.add([x, y])\r\n","\r\n","        num_filters_in = num_filters_out\r\n","\r\n","    # Add classifier on top.\r\n","    # v2 has BN-ReLU before Pooling\r\n","    x = BatchNormalization()(x)\r\n","    x = Activation('relu')(x)\r\n","    x = AveragePooling2D(pool_size=8)(x)\r\n","    y = Flatten()(x)\r\n","    outputs = Dense(num_classes,\r\n","                    activation='softmax',\r\n","                    kernel_initializer='he_normal')(y)\r\n","\r\n","    # Instantiate model.\r\n","    model = Model(inputs=inputs, outputs=outputs)\r\n","    return model\r\n","\r\n","\r\n","if version == 2:\r\n","    model = resnet_v2(input_shape=(256,256,3), depth=depth,num_classes=2)\r\n","else:\r\n","    model = resnet_v1(input_shape=(256,256,3), depth=depth,num_classes=2)\r\n","\r\n","model.compile(loss='categorical_crossentropy',\r\n","              optimizer=Adam(lr=0.01),\r\n","              metrics=['accuracy'])\r\n","model.summary()\r\n","print(model_type)\r\n","\r\n","plot_model(model, show_shapes=True, to_file='/content/drive/My Drive/model_graph_resnet.png')\r\n","\r\n","# Prepare model model saving directory.\r\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\r\n","model_name = 'covid19_%s_model.{epoch:03d}.h5' % model_type\r\n","if not os.path.isdir(save_dir):\r\n","    os.makedirs(save_dir)\r\n","filepath = os.path.join(save_dir, model_name)\r\n","\r\n","# Prepare callbacks for model saving and for learning rate adjustment.\r\n","checkpoint = ModelCheckpoint(filepath=filepath,\r\n","                             monitor='val_acc',\r\n","                             verbose=1,\r\n","                             save_best_only=True)\r\n","\r\n","lr_scheduler = LearningRateScheduler(lr_schedule)\r\n","\r\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n","                               cooldown=0,\r\n","                               patience=5,\r\n","                               min_lr=0.5e-6)\r\n","\r\n","callbacks = [checkpoint, lr_reducer, lr_scheduler]\r\n","\r\n","# Run training, with or without data augmentation.\r\n","\r\n","# This will do preprocessing and realtime data augmentation:\r\n","datagen = ImageDataGenerator(\r\n","    rotation_range=40,\r\n","        width_shift_range=0.2,\r\n","        height_shift_range=0.2,\r\n","        rescale=1./255,\r\n","        shear_range=0.2,\r\n","        zoom_range=0.2,\r\n","        horizontal_flip=True,\r\n","        fill_mode='nearest'\r\n","    )\r\n","\r\n","# Compute quantities required for featurewise normalization\r\n","# (std, mean, and principal components if ZCA whitening is applied).\r\n","train_generator=datagen.flow_from_directory(directory='/content/drive/MyDrive/CT_COVID1.1',batch_size=64)\r\n","\r\n","# Fit the model on the batches generated by datagen.flow().\r\n","history = model.fit_generator(train_generator,\r\n","                    epochs=10,\r\n","                    callbacks=callbacks)\r\n","model.save(\"/content/drive/My Drive/CTCOVID11_epoch10.h5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 256, 256, 16) 448         input_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 256, 256, 16) 64          conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 256, 256, 16) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 256, 256, 16) 2320        activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 256, 256, 16) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 256, 256, 16) 2320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 256, 256, 16) 64          conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 256, 256, 16) 0           activation[0][0]                 \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 256, 256, 16) 0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 256, 256, 16) 2320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 256, 256, 16) 64          conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 256, 256, 16) 0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 256, 256, 16) 2320        activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 256, 256, 16) 64          conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 256, 256, 16) 0           activation_2[0][0]               \n","                                                                 batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 256, 256, 16) 0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 256, 256, 16) 2320        activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 256, 256, 16) 64          conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 256, 256, 16) 0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 256, 256, 16) 2320        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 256, 256, 16) 64          conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 256, 256, 16) 0           activation_4[0][0]               \n","                                                                 batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 256, 256, 16) 0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 128, 128, 32) 4640        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 128, 128, 32) 128         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 128, 128, 32) 0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 128, 128, 32) 9248        activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 128, 128, 32) 544         activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 128, 128, 32) 128         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 128, 128, 32) 0           conv2d_9[0][0]                   \n","                                                                 batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 128, 128, 32) 0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 128, 128, 32) 9248        activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 128, 128, 32) 128         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 128, 128, 32) 0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 128, 128, 32) 9248        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 128, 128, 32) 128         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 128, 128, 32) 0           activation_8[0][0]               \n","                                                                 batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 128, 128, 32) 0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 128, 128, 32) 9248        activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 128, 128, 32) 128         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 128, 128, 32) 0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 128, 128, 32) 9248        activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 128, 128, 32) 128         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 128, 128, 32) 0           activation_10[0][0]              \n","                                                                 batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 128, 128, 32) 0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 64, 64, 64)   18496       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 64, 64, 64)   36928       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 64, 64, 64)   2112        activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 64, 64, 64)   0           conv2d_16[0][0]                  \n","                                                                 batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 64, 64, 64)   0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 64, 64, 64)   36928       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 64, 64, 64)   256         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 64, 64, 64)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 64, 64, 64)   36928       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 64, 64, 64)   256         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 64, 64, 64)   0           activation_14[0][0]              \n","                                                                 batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 64, 64, 64)   0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 64, 64, 64)   36928       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 64, 64, 64)   256         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 64, 64, 64)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 64, 64, 64)   36928       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 64, 64, 64)   256         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 64, 64, 64)   0           activation_16[0][0]              \n","                                                                 batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 64, 64, 64)   0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 8, 8, 64)     0           activation_18[0][0]              \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 4096)         0           average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2)            8194        flatten[0][0]                    \n","==================================================================================================\n","Total params: 281,986\n","Trainable params: 280,610\n","Non-trainable params: 1,376\n","__________________________________________________________________________________________________\n","ResNet20v1\n","Found 1678 images belonging to 2 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1173s 42s/step - loss: 2.1604 - accuracy: 0.6665\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 2/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1043s 39s/step - loss: 0.6895 - accuracy: 0.7761\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 3/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1047s 39s/step - loss: 0.5988 - accuracy: 0.8061\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 4/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1042s 39s/step - loss: 0.5819 - accuracy: 0.7930\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 5/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1042s 38s/step - loss: 0.6929 - accuracy: 0.7677\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 6/10\n","Learning rate:  0.001\n","20/27 [=====================>........] - ETA: 4:43 - loss: 0.5364 - accuracy: 0.8106"],"name":"stdout"},{"output_type":"error","ename":"UnknownError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-231f3f1965e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    349\u001b[0m history = model.fit_generator(train_generator,\n\u001b[1;32m    350\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/CTCOVID11_epoch10.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnknownError\u001b[0m:  FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/CT_COVID1.1/1/2 (154).jpeg'\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 807, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 933, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\", line 113, in load_img\n    with open(path, 'rb') as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/CT_COVID1.1/1/2 (154).jpeg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_5397]\n\nFunction call stack:\ntrain_function\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5SLJ7NWtbei3","executionInfo":{"elapsed":29400,"status":"ok","timestamp":1610905953989,"user":{"displayName":"covid project","photoUrl":"","userId":"04822791065494456352"},"user_tz":-330},"outputId":"efdebf32-e7aa-4c99-9ceb-611f843e9a0b"},"source":["dir = '/content/drive/MyDrive/clahe_covid_ct_test'\r\n","\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.models import load_model\r\n","import numpy as np\r\n","\r\n","\r\n","datagen = ImageDataGenerator(\r\n","    rotation_range=40,\r\n","        width_shift_range=0.2,\r\n","        height_shift_range=0.2,\r\n","        rescale=1./255,\r\n","        shear_range=0.2,\r\n","        zoom_range=0.2,\r\n","        horizontal_flip=True,\r\n","        fill_mode='nearest'\r\n","    )\r\n","\r\n","test_generator=datagen.flow_from_directory(directory=dir,batch_size=64, shuffle=False)\r\n","\r\n","y_true = test_generator.classes\r\n","\r\n","model = load_model(\"/content/drive/My Drive/covid19Resnet.h5\")\r\n","\r\n","result = model.predict_generator(test_generator)\r\n","\r\n","y_pred = np.argmax(result, axis=-1)\r\n","from sklearn.metrics import confusion_matrix\r\n","print(confusion_matrix(y_true, y_pred))\r\n","\r\n","from sklearn.metrics import classification_report\r\n","print(classification_report(y_true,y_pred))\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 150 images belonging to 2 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  warnings.warn('`Model.predict_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["[[ 49   1]\n"," [100   0]]\n","              precision    recall  f1-score   support\n","\n","           0       0.33      0.98      0.49        50\n","           1       0.00      0.00      0.00       100\n","\n","    accuracy                           0.33       150\n","   macro avg       0.16      0.49      0.25       150\n","weighted avg       0.11      0.33      0.16       150\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXuCMR1u7CC6","executionInfo":{"elapsed":10255667,"status":"ok","timestamp":1610926901628,"user":{"displayName":"covid project","photoUrl":"","userId":"04822791065494456352"},"user_tz":-330},"outputId":"4e91d6da-9cbe-46ed-b881-b7967f2b9424"},"source":["from __future__ import print_function\r\n","import keras\r\n","from keras.layers import Dense, Conv2D, BatchNormalization, Activation\r\n","from keras.layers import AveragePooling2D, Input, Flatten\r\n","from keras.optimizers import Adam\r\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n","from keras.callbacks import ReduceLROnPlateau\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.regularizers import l2\r\n","from keras import backend as K\r\n","from keras.models import Model\r\n","import numpy as np\r\n","import os\r\n","from keras.utils import plot_model\r\n","# Training parameters\r\n","batch_size = 32  # orig paper trained all networks with batch_size=128\r\n","epochs = 200\r\n","num_classes = 2\r\n","\r\n","# Subtracting pixel mean improves accuracy\r\n","subtract_pixel_mean = True\r\n","\r\n","# Model parameter\r\n","# ----------------------------------------------------------------------------\r\n","#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\r\n","# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\r\n","#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\r\n","# ----------------------------------------------------------------------------\r\n","# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\r\n","# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\r\n","# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\r\n","# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\r\n","# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\r\n","# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\r\n","# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\r\n","# ---------------------------------------------------------------------------\r\n","n = 3\r\n","\r\n","# Model version\r\n","# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\r\n","version = 1\r\n","\r\n","# Computed depth from supplied model parameter n\r\n","if version == 1:\r\n","    depth = n * 6 + 2\r\n","elif version == 2:\r\n","    depth = n * 9 + 2\r\n","\r\n","# Model name, depth and version\r\n","model_type = 'ResNet%dv%d' % (depth, version)\r\n","\r\n","# Input image dimensions.\r\n","\r\n","\r\n","def lr_schedule(epoch):\r\n","    \"\"\"Learning Rate Schedule\r\n","\r\n","    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\r\n","    Called automatically every epoch as part of callbacks during training.\r\n","\r\n","    # Arguments\r\n","        epoch (int): The number of epochs\r\n","\r\n","    # Returns\r\n","        lr (float32): learning rate\r\n","    \"\"\"\r\n","    lr = 1e-3\r\n","    if epoch > 180:\r\n","        lr *= 0.5e-3\r\n","    elif epoch > 160:\r\n","        lr *= 1e-3\r\n","    elif epoch > 120:\r\n","        lr *= 1e-2\r\n","    elif epoch > 80:\r\n","        lr *= 1e-1\r\n","    print('Learning rate: ', lr)\r\n","    return lr\r\n","\r\n","\r\n","def resnet_layer(inputs,\r\n","                 num_filters=16,\r\n","                 kernel_size=3,\r\n","                 strides=1,\r\n","                 activation='relu',\r\n","                 batch_normalization=True,\r\n","                 conv_first=True):\r\n","    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\r\n","\r\n","    # Arguments\r\n","        inputs (tensor): input tensor from input image or previous layer\r\n","        num_filters (int): Conv2D number of filters\r\n","        kernel_size (int): Conv2D square kernel dimensions\r\n","        strides (int): Conv2D square stride dimensions\r\n","        activation (string): activation name\r\n","        batch_normalization (bool): whether to include batch normalization\r\n","        conv_first (bool): conv-bn-activation (True) or\r\n","            bn-activation-conv (False)\r\n","\r\n","    # Returns\r\n","        x (tensor): tensor as input to the next layer\r\n","    \"\"\"\r\n","    conv = Conv2D(num_filters,\r\n","                  kernel_size=kernel_size,\r\n","                  strides=strides,\r\n","                  padding='same',\r\n","                  kernel_initializer='he_normal',\r\n","                  kernel_regularizer=l2(1e-4))\r\n","\r\n","    x = inputs\r\n","    if conv_first:\r\n","        x = conv(x)\r\n","        if batch_normalization:\r\n","            x = BatchNormalization()(x)\r\n","        if activation is not None:\r\n","            x = Activation(activation)(x)\r\n","    else:\r\n","        if batch_normalization:\r\n","            x = BatchNormalization()(x)\r\n","        if activation is not None:\r\n","            x = Activation(activation)(x)\r\n","        x = conv(x)\r\n","    return x\r\n","\r\n","\r\n","def resnet_v1(input_shape, depth, num_classes=2):\r\n","    \"\"\"ResNet Version 1 Model builder [a]\r\n","\r\n","    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\r\n","    Last ReLU is after the shortcut connection.\r\n","    At the beginning of each stage, the feature map size is halved (downsampled)\r\n","    by a convolutional layer with strides=2, while the number of filters is\r\n","    doubled. Within each stage, the layers have the same number filters and the\r\n","    same number of filters.\r\n","    Features maps sizes:\r\n","    stage 0: 32x32, 16\r\n","    stage 1: 16x16, 32\r\n","    stage 2:  8x8,  64\r\n","    The Number of parameters is approx the same as Table 6 of [a]:\r\n","    ResNet20 0.27M\r\n","    ResNet32 0.46M\r\n","    ResNet44 0.66M\r\n","    ResNet56 0.85M\r\n","    ResNet110 1.7M\r\n","\r\n","    # Arguments\r\n","        input_shape (tensor): shape of input image tensor\r\n","        depth (int): number of core convolutional layers\r\n","        num_classes (int): number of classes (CIFAR10 has 10)\r\n","\r\n","    # Returns\r\n","        model (Model): keras model instance\r\n","    \"\"\"\r\n","    if (depth - 2) % 6 != 0:\r\n","        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\r\n","    # Start model definition.\r\n","    num_filters = 16\r\n","    num_res_blocks = int((depth - 2) / 6)\r\n","\r\n","    inputs = Input(shape=input_shape)\r\n","    x = resnet_layer(inputs=inputs)\r\n","    # Instantiate the stack of residual units\r\n","    for stack in range(3):\r\n","        for res_block in range(num_res_blocks):\r\n","            strides = 1\r\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n","                strides = 2  # downsample\r\n","            y = resnet_layer(inputs=x,\r\n","                             num_filters=num_filters,\r\n","                             strides=strides)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters,\r\n","                             activation=None)\r\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n","                # linear projection residual shortcut connection to match\r\n","                # changed dims\r\n","                x = resnet_layer(inputs=x,\r\n","                                 num_filters=num_filters,\r\n","                                 kernel_size=1,\r\n","                                 strides=strides,\r\n","                                 activation=None,\r\n","                                 batch_normalization=False)\r\n","            x = keras.layers.add([x, y])\r\n","            x = Activation('relu')(x)\r\n","        num_filters *= 2\r\n","\r\n","    # Add classifier on top.\r\n","    # v1 does not use BN after last shortcut connection-ReLU\r\n","    x = AveragePooling2D(pool_size=8)(x)\r\n","    y = Flatten()(x)\r\n","    outputs = Dense(num_classes,\r\n","                    activation='softmax',\r\n","                    kernel_initializer='he_normal')(y)\r\n","\r\n","    # Instantiate model.\r\n","    model = Model(inputs=inputs, outputs=outputs)\r\n","    return model\r\n","\r\n","\r\n","def resnet_v2(input_shape, depth, num_classes=2):\r\n","    \"\"\"ResNet Version 2 Model builder [b]\r\n","\r\n","    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\r\n","    bottleneck layer\r\n","    First shortcut connection per layer is 1 x 1 Conv2D.\r\n","    Second and onwards shortcut connection is identity.\r\n","    At the beginning of each stage, the feature map size is halved (downsampled)\r\n","    by a convolutional layer with strides=2, while the number of filter maps is\r\n","    doubled. Within each stage, the layers have the same number filters and the\r\n","    same filter map sizes.\r\n","    Features maps sizes:\r\n","    conv1  : 32x32,  16\r\n","    stage 0: 32x32,  64\r\n","    stage 1: 16x16, 128\r\n","    stage 2:  8x8,  256\r\n","\r\n","    # Arguments\r\n","        input_shape (tensor): shape of input image tensor\r\n","        depth (int): number of core convolutional layers\r\n","        num_classes (int): number of classes (CIFAR10 has 10)\r\n","\r\n","    # Returns\r\n","        model (Model): keras model instance\r\n","    \"\"\"\r\n","    if (depth - 2) % 9 != 0:\r\n","        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\r\n","    # Start model definition.\r\n","    num_filters_in = 16\r\n","    num_res_blocks = int((depth - 2) / 9)\r\n","\r\n","    inputs = Input(shape=input_shape)\r\n","    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\r\n","    x = resnet_layer(inputs=inputs,\r\n","                     num_filters=num_filters_in,\r\n","                     conv_first=True)\r\n","\r\n","    # Instantiate the stack of residual units\r\n","    for stage in range(3):\r\n","        for res_block in range(num_res_blocks):\r\n","            activation = 'relu'\r\n","            batch_normalization = True\r\n","            strides = 1\r\n","            if stage == 0:\r\n","                num_filters_out = num_filters_in * 4\r\n","                if res_block == 0:  # first layer and first stage\r\n","                    activation = None\r\n","                    batch_normalization = False\r\n","            else:\r\n","                num_filters_out = num_filters_in * 2\r\n","                if res_block == 0:  # first layer but not first stage\r\n","                    strides = 2    # downsample\r\n","\r\n","            # bottleneck residual unit\r\n","            y = resnet_layer(inputs=x,\r\n","                             num_filters=num_filters_in,\r\n","                             kernel_size=1,\r\n","                             strides=strides,\r\n","                             activation=activation,\r\n","                             batch_normalization=batch_normalization,\r\n","                             conv_first=False)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters_in,\r\n","                             conv_first=False)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters_out,\r\n","                             kernel_size=1,\r\n","                             conv_first=False)\r\n","            if res_block == 0:\r\n","                # linear projection residual shortcut connection to match\r\n","                # changed dims\r\n","                x = resnet_layer(inputs=x,\r\n","                                 num_filters=num_filters_out,\r\n","                                 kernel_size=1,\r\n","                                 strides=strides,\r\n","                                 activation=None,\r\n","                                 batch_normalization=False)\r\n","            x = keras.layers.add([x, y])\r\n","\r\n","        num_filters_in = num_filters_out\r\n","\r\n","    # Add classifier on top.\r\n","    # v2 has BN-ReLU before Pooling\r\n","    x = BatchNormalization()(x)\r\n","    x = Activation('relu')(x)\r\n","    x = AveragePooling2D(pool_size=8)(x)\r\n","    y = Flatten()(x)\r\n","    outputs = Dense(num_classes,\r\n","                    activation='softmax',\r\n","                    kernel_initializer='he_normal')(y)\r\n","\r\n","    # Instantiate model.\r\n","    model = Model(inputs=inputs, outputs=outputs)\r\n","    return model\r\n","\r\n","\r\n","if version == 2:\r\n","    model = resnet_v2(input_shape=(256,256,3), depth=depth,num_classes=2)\r\n","else:\r\n","    model = resnet_v1(input_shape=(256,256,3), depth=depth,num_classes=2)\r\n","\r\n","model.compile(loss='categorical_crossentropy',\r\n","              optimizer=Adam(lr=0.01),\r\n","              metrics=['accuracy'])\r\n","model.summary()\r\n","print(model_type)\r\n","\r\n","plot_model(model, show_shapes=True, to_file='/content/drive/My Drive/model_graph_resnet.png')\r\n","\r\n","# Prepare model model saving directory.\r\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\r\n","model_name = 'covid19_%s_model.{epoch:03d}.h5' % model_type\r\n","if not os.path.isdir(save_dir):\r\n","    os.makedirs(save_dir)\r\n","filepath = os.path.join(save_dir, model_name)\r\n","\r\n","# Prepare callbacks for model saving and for learning rate adjustment.\r\n","checkpoint = ModelCheckpoint(filepath=filepath,\r\n","                             monitor='val_acc',\r\n","                             verbose=1,\r\n","                             save_best_only=True)\r\n","\r\n","lr_scheduler = LearningRateScheduler(lr_schedule)\r\n","\r\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n","                               cooldown=0,\r\n","                               patience=5,\r\n","                               min_lr=0.5e-6)\r\n","\r\n","callbacks = [checkpoint, lr_reducer, lr_scheduler]\r\n","\r\n","# Run training, with or without data augmentation.\r\n","\r\n","# This will do preprocessing and realtime data augmentation:\r\n","datagen = ImageDataGenerator(\r\n","    rotation_range=40,\r\n","        width_shift_range=0.2,\r\n","        height_shift_range=0.2,\r\n","        rescale=1./255,\r\n","        shear_range=0.2,\r\n","        zoom_range=0.2,\r\n","        horizontal_flip=True,\r\n","        fill_mode='nearest'\r\n","    )\r\n","\r\n","# Compute quantities required for featurewise normalization\r\n","# (std, mean, and principal components if ZCA whitening is applied).\r\n","train_generator=datagen.flow_from_directory(directory='/content/drive/MyDrive/clahe_covid_ct_1.3',batch_size=64)\r\n","\r\n","# Fit the model on the batches generated by datagen.flow().\r\n","history = model.fit_generator(train_generator,\r\n","                    epochs=10,\r\n","                    callbacks=callbacks)\r\n","model.save(\"/content/drive/My Drive/covid19clahe13Resnet_epoch10.h5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_63 (Conv2D)              (None, 256, 256, 16) 448         input_4[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_57 (BatchNo (None, 256, 256, 16) 64          conv2d_63[0][0]                  \n","__________________________________________________________________________________________________\n","activation_57 (Activation)      (None, 256, 256, 16) 0           batch_normalization_57[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_64 (Conv2D)              (None, 256, 256, 16) 2320        activation_57[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_58 (BatchNo (None, 256, 256, 16) 64          conv2d_64[0][0]                  \n","__________________________________________________________________________________________________\n","activation_58 (Activation)      (None, 256, 256, 16) 0           batch_normalization_58[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_65 (Conv2D)              (None, 256, 256, 16) 2320        activation_58[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_59 (BatchNo (None, 256, 256, 16) 64          conv2d_65[0][0]                  \n","__________________________________________________________________________________________________\n","add_27 (Add)                    (None, 256, 256, 16) 0           activation_57[0][0]              \n","                                                                 batch_normalization_59[0][0]     \n","__________________________________________________________________________________________________\n","activation_59 (Activation)      (None, 256, 256, 16) 0           add_27[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_66 (Conv2D)              (None, 256, 256, 16) 2320        activation_59[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_60 (BatchNo (None, 256, 256, 16) 64          conv2d_66[0][0]                  \n","__________________________________________________________________________________________________\n","activation_60 (Activation)      (None, 256, 256, 16) 0           batch_normalization_60[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_67 (Conv2D)              (None, 256, 256, 16) 2320        activation_60[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_61 (BatchNo (None, 256, 256, 16) 64          conv2d_67[0][0]                  \n","__________________________________________________________________________________________________\n","add_28 (Add)                    (None, 256, 256, 16) 0           activation_59[0][0]              \n","                                                                 batch_normalization_61[0][0]     \n","__________________________________________________________________________________________________\n","activation_61 (Activation)      (None, 256, 256, 16) 0           add_28[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_68 (Conv2D)              (None, 256, 256, 16) 2320        activation_61[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_62 (BatchNo (None, 256, 256, 16) 64          conv2d_68[0][0]                  \n","__________________________________________________________________________________________________\n","activation_62 (Activation)      (None, 256, 256, 16) 0           batch_normalization_62[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_69 (Conv2D)              (None, 256, 256, 16) 2320        activation_62[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_63 (BatchNo (None, 256, 256, 16) 64          conv2d_69[0][0]                  \n","__________________________________________________________________________________________________\n","add_29 (Add)                    (None, 256, 256, 16) 0           activation_61[0][0]              \n","                                                                 batch_normalization_63[0][0]     \n","__________________________________________________________________________________________________\n","activation_63 (Activation)      (None, 256, 256, 16) 0           add_29[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_70 (Conv2D)              (None, 128, 128, 32) 4640        activation_63[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_64 (BatchNo (None, 128, 128, 32) 128         conv2d_70[0][0]                  \n","__________________________________________________________________________________________________\n","activation_64 (Activation)      (None, 128, 128, 32) 0           batch_normalization_64[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_71 (Conv2D)              (None, 128, 128, 32) 9248        activation_64[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_72 (Conv2D)              (None, 128, 128, 32) 544         activation_63[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_65 (BatchNo (None, 128, 128, 32) 128         conv2d_71[0][0]                  \n","__________________________________________________________________________________________________\n","add_30 (Add)                    (None, 128, 128, 32) 0           conv2d_72[0][0]                  \n","                                                                 batch_normalization_65[0][0]     \n","__________________________________________________________________________________________________\n","activation_65 (Activation)      (None, 128, 128, 32) 0           add_30[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_73 (Conv2D)              (None, 128, 128, 32) 9248        activation_65[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_66 (BatchNo (None, 128, 128, 32) 128         conv2d_73[0][0]                  \n","__________________________________________________________________________________________________\n","activation_66 (Activation)      (None, 128, 128, 32) 0           batch_normalization_66[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_74 (Conv2D)              (None, 128, 128, 32) 9248        activation_66[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_67 (BatchNo (None, 128, 128, 32) 128         conv2d_74[0][0]                  \n","__________________________________________________________________________________________________\n","add_31 (Add)                    (None, 128, 128, 32) 0           activation_65[0][0]              \n","                                                                 batch_normalization_67[0][0]     \n","__________________________________________________________________________________________________\n","activation_67 (Activation)      (None, 128, 128, 32) 0           add_31[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_75 (Conv2D)              (None, 128, 128, 32) 9248        activation_67[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_68 (BatchNo (None, 128, 128, 32) 128         conv2d_75[0][0]                  \n","__________________________________________________________________________________________________\n","activation_68 (Activation)      (None, 128, 128, 32) 0           batch_normalization_68[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_76 (Conv2D)              (None, 128, 128, 32) 9248        activation_68[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_69 (BatchNo (None, 128, 128, 32) 128         conv2d_76[0][0]                  \n","__________________________________________________________________________________________________\n","add_32 (Add)                    (None, 128, 128, 32) 0           activation_67[0][0]              \n","                                                                 batch_normalization_69[0][0]     \n","__________________________________________________________________________________________________\n","activation_69 (Activation)      (None, 128, 128, 32) 0           add_32[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_77 (Conv2D)              (None, 64, 64, 64)   18496       activation_69[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_70 (BatchNo (None, 64, 64, 64)   256         conv2d_77[0][0]                  \n","__________________________________________________________________________________________________\n","activation_70 (Activation)      (None, 64, 64, 64)   0           batch_normalization_70[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_78 (Conv2D)              (None, 64, 64, 64)   36928       activation_70[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_79 (Conv2D)              (None, 64, 64, 64)   2112        activation_69[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_71 (BatchNo (None, 64, 64, 64)   256         conv2d_78[0][0]                  \n","__________________________________________________________________________________________________\n","add_33 (Add)                    (None, 64, 64, 64)   0           conv2d_79[0][0]                  \n","                                                                 batch_normalization_71[0][0]     \n","__________________________________________________________________________________________________\n","activation_71 (Activation)      (None, 64, 64, 64)   0           add_33[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_80 (Conv2D)              (None, 64, 64, 64)   36928       activation_71[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_72 (BatchNo (None, 64, 64, 64)   256         conv2d_80[0][0]                  \n","__________________________________________________________________________________________________\n","activation_72 (Activation)      (None, 64, 64, 64)   0           batch_normalization_72[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_81 (Conv2D)              (None, 64, 64, 64)   36928       activation_72[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_73 (BatchNo (None, 64, 64, 64)   256         conv2d_81[0][0]                  \n","__________________________________________________________________________________________________\n","add_34 (Add)                    (None, 64, 64, 64)   0           activation_71[0][0]              \n","                                                                 batch_normalization_73[0][0]     \n","__________________________________________________________________________________________________\n","activation_73 (Activation)      (None, 64, 64, 64)   0           add_34[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_82 (Conv2D)              (None, 64, 64, 64)   36928       activation_73[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_74 (BatchNo (None, 64, 64, 64)   256         conv2d_82[0][0]                  \n","__________________________________________________________________________________________________\n","activation_74 (Activation)      (None, 64, 64, 64)   0           batch_normalization_74[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_83 (Conv2D)              (None, 64, 64, 64)   36928       activation_74[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_75 (BatchNo (None, 64, 64, 64)   256         conv2d_83[0][0]                  \n","__________________________________________________________________________________________________\n","add_35 (Add)                    (None, 64, 64, 64)   0           activation_73[0][0]              \n","                                                                 batch_normalization_75[0][0]     \n","__________________________________________________________________________________________________\n","activation_75 (Activation)      (None, 64, 64, 64)   0           add_35[0][0]                     \n","__________________________________________________________________________________________________\n","average_pooling2d_3 (AveragePoo (None, 8, 8, 64)     0           activation_75[0][0]              \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 4096)         0           average_pooling2d_3[0][0]        \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 2)            8194        flatten_3[0][0]                  \n","==================================================================================================\n","Total params: 281,986\n","Trainable params: 280,610\n","Non-trainable params: 1,376\n","__________________________________________________________________________________________________\n","ResNet20v1\n","Found 1727 images belonging to 2 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1146s 41s/step - loss: 1.9203 - accuracy: 0.6483\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 2/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1014s 38s/step - loss: 0.6264 - accuracy: 0.7972\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 3/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1012s 37s/step - loss: 0.6818 - accuracy: 0.7872\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 4/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1014s 38s/step - loss: 0.6556 - accuracy: 0.8154\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 5/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1015s 38s/step - loss: 0.5572 - accuracy: 0.8317\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 6/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1002s 37s/step - loss: 0.5347 - accuracy: 0.8438\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 7/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1002s 37s/step - loss: 0.5227 - accuracy: 0.8310\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 8/10\n","Learning rate:  0.001\n","27/27 [==============================] - 999s 37s/step - loss: 0.5398 - accuracy: 0.8383\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 9/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1000s 37s/step - loss: 0.4950 - accuracy: 0.8644\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 10/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1005s 37s/step - loss: 0.4845 - accuracy: 0.8511\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Zino0rHKWx-s","outputId":"b8a057e2-ad06-4197-f558-eefb9ab3100f"},"source":["from __future__ import print_function\r\n","import keras\r\n","from keras.layers import Dense, Conv2D, BatchNormalization, Activation\r\n","from keras.layers import AveragePooling2D, Input, Flatten\r\n","from keras.optimizers import Adam\r\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n","from keras.callbacks import ReduceLROnPlateau\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.regularizers import l2\r\n","from keras import backend as K\r\n","from keras.models import Model\r\n","import numpy as np\r\n","import os\r\n","from keras.utils import plot_model\r\n","# Training parameters\r\n","batch_size = 32  # orig paper trained all networks with batch_size=128\r\n","epochs = 200\r\n","num_classes = 2\r\n","\r\n","# Subtracting pixel mean improves accuracy\r\n","subtract_pixel_mean = True\r\n","\r\n","# Model parameter\r\n","# ----------------------------------------------------------------------------\r\n","#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\r\n","# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\r\n","#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\r\n","# ----------------------------------------------------------------------------\r\n","# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\r\n","# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\r\n","# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\r\n","# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\r\n","# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\r\n","# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\r\n","# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\r\n","# ---------------------------------------------------------------------------\r\n","n = 3\r\n","\r\n","# Model version\r\n","# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\r\n","version = 1\r\n","\r\n","# Computed depth from supplied model parameter n\r\n","if version == 1:\r\n","    depth = n * 6 + 2\r\n","elif version == 2:\r\n","    depth = n * 9 + 2\r\n","\r\n","# Model name, depth and version\r\n","model_type = 'ResNet%dv%d' % (depth, version)\r\n","\r\n","# Input image dimensions.\r\n","\r\n","\r\n","def lr_schedule(epoch):\r\n","    \"\"\"Learning Rate Schedule\r\n","\r\n","    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\r\n","    Called automatically every epoch as part of callbacks during training.\r\n","\r\n","    # Arguments\r\n","        epoch (int): The number of epochs\r\n","\r\n","    # Returns\r\n","        lr (float32): learning rate\r\n","    \"\"\"\r\n","    lr = 1e-3\r\n","    if epoch > 180:\r\n","        lr *= 0.5e-3\r\n","    elif epoch > 160:\r\n","        lr *= 1e-3\r\n","    elif epoch > 120:\r\n","        lr *= 1e-2\r\n","    elif epoch > 80:\r\n","        lr *= 1e-1\r\n","    print('Learning rate: ', lr)\r\n","    return lr\r\n","\r\n","\r\n","def resnet_layer(inputs,\r\n","                 num_filters=16,\r\n","                 kernel_size=3,\r\n","                 strides=1,\r\n","                 activation='relu',\r\n","                 batch_normalization=True,\r\n","                 conv_first=True):\r\n","    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\r\n","\r\n","    # Arguments\r\n","        inputs (tensor): input tensor from input image or previous layer\r\n","        num_filters (int): Conv2D number of filters\r\n","        kernel_size (int): Conv2D square kernel dimensions\r\n","        strides (int): Conv2D square stride dimensions\r\n","        activation (string): activation name\r\n","        batch_normalization (bool): whether to include batch normalization\r\n","        conv_first (bool): conv-bn-activation (True) or\r\n","            bn-activation-conv (False)\r\n","\r\n","    # Returns\r\n","        x (tensor): tensor as input to the next layer\r\n","    \"\"\"\r\n","    conv = Conv2D(num_filters,\r\n","                  kernel_size=kernel_size,\r\n","                  strides=strides,\r\n","                  padding='same',\r\n","                  kernel_initializer='he_normal',\r\n","                  kernel_regularizer=l2(1e-4))\r\n","\r\n","    x = inputs\r\n","    if conv_first:\r\n","        x = conv(x)\r\n","        if batch_normalization:\r\n","            x = BatchNormalization()(x)\r\n","        if activation is not None:\r\n","            x = Activation(activation)(x)\r\n","    else:\r\n","        if batch_normalization:\r\n","            x = BatchNormalization()(x)\r\n","        if activation is not None:\r\n","            x = Activation(activation)(x)\r\n","        x = conv(x)\r\n","    return x\r\n","\r\n","\r\n","def resnet_v1(input_shape, depth, num_classes=2):\r\n","    \"\"\"ResNet Version 1 Model builder [a]\r\n","\r\n","    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\r\n","    Last ReLU is after the shortcut connection.\r\n","    At the beginning of each stage, the feature map size is halved (downsampled)\r\n","    by a convolutional layer with strides=2, while the number of filters is\r\n","    doubled. Within each stage, the layers have the same number filters and the\r\n","    same number of filters.\r\n","    Features maps sizes:\r\n","    stage 0: 32x32, 16\r\n","    stage 1: 16x16, 32\r\n","    stage 2:  8x8,  64\r\n","    The Number of parameters is approx the same as Table 6 of [a]:\r\n","    ResNet20 0.27M\r\n","    ResNet32 0.46M\r\n","    ResNet44 0.66M\r\n","    ResNet56 0.85M\r\n","    ResNet110 1.7M\r\n","\r\n","    # Arguments\r\n","        input_shape (tensor): shape of input image tensor\r\n","        depth (int): number of core convolutional layers\r\n","        num_classes (int): number of classes (CIFAR10 has 10)\r\n","\r\n","    # Returns\r\n","        model (Model): keras model instance\r\n","    \"\"\"\r\n","    if (depth - 2) % 6 != 0:\r\n","        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\r\n","    # Start model definition.\r\n","    num_filters = 16\r\n","    num_res_blocks = int((depth - 2) / 6)\r\n","\r\n","    inputs = Input(shape=input_shape)\r\n","    x = resnet_layer(inputs=inputs)\r\n","    # Instantiate the stack of residual units\r\n","    for stack in range(3):\r\n","        for res_block in range(num_res_blocks):\r\n","            strides = 1\r\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n","                strides = 2  # downsample\r\n","            y = resnet_layer(inputs=x,\r\n","                             num_filters=num_filters,\r\n","                             strides=strides)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters,\r\n","                             activation=None)\r\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n","                # linear projection residual shortcut connection to match\r\n","                # changed dims\r\n","                x = resnet_layer(inputs=x,\r\n","                                 num_filters=num_filters,\r\n","                                 kernel_size=1,\r\n","                                 strides=strides,\r\n","                                 activation=None,\r\n","                                 batch_normalization=False)\r\n","            x = keras.layers.add([x, y])\r\n","            x = Activation('relu')(x)\r\n","        num_filters *= 2\r\n","\r\n","    # Add classifier on top.\r\n","    # v1 does not use BN after last shortcut connection-ReLU\r\n","    x = AveragePooling2D(pool_size=8)(x)\r\n","    y = Flatten()(x)\r\n","    outputs = Dense(num_classes,\r\n","                    activation='softmax',\r\n","                    kernel_initializer='he_normal')(y)\r\n","\r\n","    # Instantiate model.\r\n","    model = Model(inputs=inputs, outputs=outputs)\r\n","    return model\r\n","\r\n","\r\n","def resnet_v2(input_shape, depth, num_classes=2):\r\n","    \"\"\"ResNet Version 2 Model builder [b]\r\n","\r\n","    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\r\n","    bottleneck layer\r\n","    First shortcut connection per layer is 1 x 1 Conv2D.\r\n","    Second and onwards shortcut connection is identity.\r\n","    At the beginning of each stage, the feature map size is halved (downsampled)\r\n","    by a convolutional layer with strides=2, while the number of filter maps is\r\n","    doubled. Within each stage, the layers have the same number filters and the\r\n","    same filter map sizes.\r\n","    Features maps sizes:\r\n","    conv1  : 32x32,  16\r\n","    stage 0: 32x32,  64\r\n","    stage 1: 16x16, 128\r\n","    stage 2:  8x8,  256\r\n","\r\n","    # Arguments\r\n","        input_shape (tensor): shape of input image tensor\r\n","        depth (int): number of core convolutional layers\r\n","        num_classes (int): number of classes (CIFAR10 has 10)\r\n","\r\n","    # Returns\r\n","        model (Model): keras model instance\r\n","    \"\"\"\r\n","    if (depth - 2) % 9 != 0:\r\n","        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\r\n","    # Start model definition.\r\n","    num_filters_in = 16\r\n","    num_res_blocks = int((depth - 2) / 9)\r\n","\r\n","    inputs = Input(shape=input_shape)\r\n","    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\r\n","    x = resnet_layer(inputs=inputs,\r\n","                     num_filters=num_filters_in,\r\n","                     conv_first=True)\r\n","\r\n","    # Instantiate the stack of residual units\r\n","    for stage in range(3):\r\n","        for res_block in range(num_res_blocks):\r\n","            activation = 'relu'\r\n","            batch_normalization = True\r\n","            strides = 1\r\n","            if stage == 0:\r\n","                num_filters_out = num_filters_in * 4\r\n","                if res_block == 0:  # first layer and first stage\r\n","                    activation = None\r\n","                    batch_normalization = False\r\n","            else:\r\n","                num_filters_out = num_filters_in * 2\r\n","                if res_block == 0:  # first layer but not first stage\r\n","                    strides = 2    # downsample\r\n","\r\n","            # bottleneck residual unit\r\n","            y = resnet_layer(inputs=x,\r\n","                             num_filters=num_filters_in,\r\n","                             kernel_size=1,\r\n","                             strides=strides,\r\n","                             activation=activation,\r\n","                             batch_normalization=batch_normalization,\r\n","                             conv_first=False)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters_in,\r\n","                             conv_first=False)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters_out,\r\n","                             kernel_size=1,\r\n","                             conv_first=False)\r\n","            if res_block == 0:\r\n","                # linear projection residual shortcut connection to match\r\n","                # changed dims\r\n","                x = resnet_layer(inputs=x,\r\n","                                 num_filters=num_filters_out,\r\n","                                 kernel_size=1,\r\n","                                 strides=strides,\r\n","                                 activation=None,\r\n","                                 batch_normalization=False)\r\n","            x = keras.layers.add([x, y])\r\n","\r\n","        num_filters_in = num_filters_out\r\n","\r\n","    # Add classifier on top.\r\n","    # v2 has BN-ReLU before Pooling\r\n","    x = BatchNormalization()(x)\r\n","    x = Activation('relu')(x)\r\n","    x = AveragePooling2D(pool_size=8)(x)\r\n","    y = Flatten()(x)\r\n","    outputs = Dense(num_classes,\r\n","                    activation='softmax',\r\n","                    kernel_initializer='he_normal')(y)\r\n","\r\n","    # Instantiate model.\r\n","    model = Model(inputs=inputs, outputs=outputs)\r\n","    return model\r\n","\r\n","\r\n","if version == 2:\r\n","    model = resnet_v2(input_shape=(256,256,3), depth=depth,num_classes=2)\r\n","else:\r\n","    model = resnet_v1(input_shape=(256,256,3), depth=depth,num_classes=2)\r\n","\r\n","model.compile(loss='categorical_crossentropy',\r\n","              optimizer=Adam(lr=0.01),\r\n","              metrics=['accuracy'])\r\n","model.summary()\r\n","print(model_type)\r\n","\r\n","plot_model(model, show_shapes=True, to_file='/content/drive/My Drive/model_graph_resnet.png')\r\n","\r\n","# Prepare model model saving directory.\r\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\r\n","model_name = 'covid19_%s_model.{epoch:03d}.h5' % model_type\r\n","if not os.path.isdir(save_dir):\r\n","    os.makedirs(save_dir)\r\n","filepath = os.path.join(save_dir, model_name)\r\n","\r\n","# Prepare callbacks for model saving and for learning rate adjustment.\r\n","checkpoint = ModelCheckpoint(filepath=filepath,\r\n","                             monitor='val_acc',\r\n","                             verbose=1,\r\n","                             save_best_only=True)\r\n","\r\n","lr_scheduler = LearningRateScheduler(lr_schedule)\r\n","\r\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n","                               cooldown=0,\r\n","                               patience=5,\r\n","                               min_lr=0.5e-6)\r\n","\r\n","callbacks = [checkpoint, lr_reducer, lr_scheduler]\r\n","\r\n","# Run training, with or without data augmentation.\r\n","\r\n","# This will do preprocessing and realtime data augmentation:\r\n","datagen = ImageDataGenerator(\r\n","    rotation_range=40,\r\n","        width_shift_range=0.2,\r\n","        height_shift_range=0.2,\r\n","        rescale=1./255,\r\n","        shear_range=0.2,\r\n","        zoom_range=0.2,\r\n","        horizontal_flip=True,\r\n","        fill_mode='nearest'\r\n","    )\r\n","\r\n","# Compute quantities required for featurewise normalization\r\n","# (std, mean, and principal components if ZCA whitening is applied).\r\n","train_generator=datagen.flow_from_directory(directory='/content/drive/MyDrive/clahe_covid_ct_1.4',batch_size=64)\r\n","\r\n","# Fit the model on the batches generated by datagen.flow().\r\n","history = model.fit_generator(train_generator,\r\n","                    epochs=10,\r\n","                    callbacks=callbacks)\r\n","model.save(\"/content/drive/My Drive/covid19clahe14Resnet_epoch10.h5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 256, 256, 16) 448         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 256, 256, 16) 64          conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 256, 256, 16) 0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 256, 256, 16) 2320        activation[0][0]                 \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 256, 256, 16) 0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 256, 256, 16) 2320        activation_1[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 256, 256, 16) 64          conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 256, 256, 16) 0           activation[0][0]                 \n","                                                                 batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 256, 256, 16) 0           add[0][0]                        \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 256, 256, 16) 2320        activation_2[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 256, 256, 16) 64          conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 256, 256, 16) 0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 256, 256, 16) 2320        activation_3[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 256, 256, 16) 64          conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 256, 256, 16) 0           activation_2[0][0]               \n","                                                                 batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 256, 256, 16) 0           add_1[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 256, 256, 16) 2320        activation_4[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_5 (BatchNor (None, 256, 256, 16) 64          conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 256, 256, 16) 0           batch_normalization_5[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 256, 256, 16) 2320        activation_5[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_6 (BatchNor (None, 256, 256, 16) 64          conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 256, 256, 16) 0           activation_4[0][0]               \n","                                                                 batch_normalization_6[0][0]      \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 256, 256, 16) 0           add_2[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 128, 128, 32) 4640        activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_7 (BatchNor (None, 128, 128, 32) 128         conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 128, 128, 32) 0           batch_normalization_7[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 128, 128, 32) 9248        activation_7[0][0]               \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 128, 128, 32) 544         activation_6[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 128, 128, 32) 128         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 128, 128, 32) 0           conv2d_9[0][0]                   \n","                                                                 batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","activation_8 (Activation)       (None, 128, 128, 32) 0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 128, 128, 32) 9248        activation_8[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 128, 128, 32) 128         conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","activation_9 (Activation)       (None, 128, 128, 32) 0           batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 128, 128, 32) 9248        activation_9[0][0]               \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 128, 128, 32) 128         conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 128, 128, 32) 0           activation_8[0][0]               \n","                                                                 batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","activation_10 (Activation)      (None, 128, 128, 32) 0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 128, 128, 32) 9248        activation_10[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 128, 128, 32) 128         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","activation_11 (Activation)      (None, 128, 128, 32) 0           batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 128, 128, 32) 9248        activation_11[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 128, 128, 32) 128         conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 128, 128, 32) 0           activation_10[0][0]              \n","                                                                 batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 128, 128, 32) 0           add_5[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 64, 64, 64)   18496       activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 64, 64, 64)   36928       activation_13[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 64, 64, 64)   2112        activation_12[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","add_6 (Add)                     (None, 64, 64, 64)   0           conv2d_16[0][0]                  \n","                                                                 batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 64, 64, 64)   0           add_6[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 64, 64, 64)   36928       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 64, 64, 64)   256         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 64, 64, 64)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 64, 64, 64)   36928       activation_15[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 64, 64, 64)   256         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","add_7 (Add)                     (None, 64, 64, 64)   0           activation_14[0][0]              \n","                                                                 batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 64, 64, 64)   0           add_7[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 64, 64, 64)   36928       activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 64, 64, 64)   256         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 64, 64, 64)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 64, 64, 64)   36928       activation_17[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 64, 64, 64)   256         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","add_8 (Add)                     (None, 64, 64, 64)   0           activation_16[0][0]              \n","                                                                 batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 64, 64, 64)   0           add_8[0][0]                      \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 8, 8, 64)     0           activation_18[0][0]              \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 4096)         0           average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 2)            8194        flatten[0][0]                    \n","==================================================================================================\n","Total params: 281,986\n","Trainable params: 280,610\n","Non-trainable params: 1,376\n","__________________________________________________________________________________________________\n","ResNet20v1\n","Found 1728 images belonging to 2 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1594s 57s/step - loss: 1.8530 - accuracy: 0.6767\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 2/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1391s 51s/step - loss: 0.6794 - accuracy: 0.8042\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 3/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1368s 51s/step - loss: 0.6298 - accuracy: 0.7988\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 4/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1373s 51s/step - loss: 0.6053 - accuracy: 0.8107\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 5/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1357s 50s/step - loss: 0.5209 - accuracy: 0.8491\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 6/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1359s 50s/step - loss: 0.5218 - accuracy: 0.8514\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 7/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1372s 51s/step - loss: 0.5127 - accuracy: 0.8614\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 8/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1393s 52s/step - loss: 0.4948 - accuracy: 0.8466\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 9/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1395s 52s/step - loss: 0.4802 - accuracy: 0.8665\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 10/10\n","Learning rate:  0.001\n","27/27 [==============================] - 1384s 51s/step - loss: 0.4586 - accuracy: 0.8794\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FGgCMaBPNFSY","executionInfo":{"status":"ok","timestamp":1611484128608,"user_tz":-330,"elapsed":1136622,"user":{"displayName":"covid project","photoUrl":"","userId":"04822791065494456352"}},"outputId":"caaba5c0-fc92-469a-fcfb-996c3c365f6f"},"source":["from __future__ import print_function\r\n","import keras\r\n","from keras.layers import Dense, Conv2D, BatchNormalization, Activation\r\n","from keras.layers import AveragePooling2D, Input, Flatten\r\n","from keras.optimizers import Adam\r\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\r\n","from keras.callbacks import ReduceLROnPlateau\r\n","from keras.preprocessing.image import ImageDataGenerator\r\n","from keras.regularizers import l2\r\n","from keras import backend as K\r\n","from keras.models import Model\r\n","import numpy as np\r\n","import os\r\n","from keras.utils import plot_model\r\n","# Training parameters\r\n","batch_size = 32  # orig paper trained all networks with batch_size=128\r\n","epochs = 200\r\n","num_classes = 2\r\n","\r\n","# Subtracting pixel mean improves accuracy\r\n","subtract_pixel_mean = True\r\n","\r\n","# Model parameter\r\n","# ----------------------------------------------------------------------------\r\n","#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\r\n","# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\r\n","#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\r\n","# ----------------------------------------------------------------------------\r\n","# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\r\n","# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\r\n","# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\r\n","# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\r\n","# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\r\n","# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\r\n","# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\r\n","# ---------------------------------------------------------------------------\r\n","n = 3\r\n","\r\n","# Model version\r\n","# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\r\n","version = 1\r\n","\r\n","# Computed depth from supplied model parameter n\r\n","if version == 1:\r\n","    depth = n * 6 + 2\r\n","elif version == 2:\r\n","    depth = n * 9 + 2\r\n","\r\n","# Model name, depth and version\r\n","model_type = 'ResNet%dv%d' % (depth, version)\r\n","\r\n","# Input image dimensions.\r\n","\r\n","\r\n","def lr_schedule(epoch):\r\n","    \"\"\"Learning Rate Schedule\r\n","\r\n","    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\r\n","    Called automatically every epoch as part of callbacks during training.\r\n","\r\n","    # Arguments\r\n","        epoch (int): The number of epochs\r\n","\r\n","    # Returns\r\n","        lr (float32): learning rate\r\n","    \"\"\"\r\n","    lr = 1e-3\r\n","    if epoch > 180:\r\n","        lr *= 0.5e-3\r\n","    elif epoch > 160:\r\n","        lr *= 1e-3\r\n","    elif epoch > 120:\r\n","        lr *= 1e-2\r\n","    elif epoch > 80:\r\n","        lr *= 1e-1\r\n","    print('Learning rate: ', lr)\r\n","    return lr\r\n","\r\n","\r\n","def resnet_layer(inputs,\r\n","                 num_filters=16,\r\n","                 kernel_size=3,\r\n","                 strides=1,\r\n","                 activation='relu',\r\n","                 batch_normalization=True,\r\n","                 conv_first=True):\r\n","    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\r\n","\r\n","    # Arguments\r\n","        inputs (tensor): input tensor from input image or previous layer\r\n","        num_filters (int): Conv2D number of filters\r\n","        kernel_size (int): Conv2D square kernel dimensions\r\n","        strides (int): Conv2D square stride dimensions\r\n","        activation (string): activation name\r\n","        batch_normalization (bool): whether to include batch normalization\r\n","        conv_first (bool): conv-bn-activation (True) or\r\n","            bn-activation-conv (False)\r\n","\r\n","    # Returns\r\n","        x (tensor): tensor as input to the next layer\r\n","    \"\"\"\r\n","    conv = Conv2D(num_filters,\r\n","                  kernel_size=kernel_size,\r\n","                  strides=strides,\r\n","                  padding='same',\r\n","                  kernel_initializer='he_normal',\r\n","                  kernel_regularizer=l2(1e-4))\r\n","\r\n","    x = inputs\r\n","    if conv_first:\r\n","        x = conv(x)\r\n","        if batch_normalization:\r\n","            x = BatchNormalization()(x)\r\n","        if activation is not None:\r\n","            x = Activation(activation)(x)\r\n","    else:\r\n","        if batch_normalization:\r\n","            x = BatchNormalization()(x)\r\n","        if activation is not None:\r\n","            x = Activation(activation)(x)\r\n","        x = conv(x)\r\n","    return x\r\n","\r\n","\r\n","def resnet_v1(input_shape, depth, num_classes=2):\r\n","    \"\"\"ResNet Version 1 Model builder [a]\r\n","\r\n","    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\r\n","    Last ReLU is after the shortcut connection.\r\n","    At the beginning of each stage, the feature map size is halved (downsampled)\r\n","    by a convolutional layer with strides=2, while the number of filters is\r\n","    doubled. Within each stage, the layers have the same number filters and the\r\n","    same number of filters.\r\n","    Features maps sizes:\r\n","    stage 0: 32x32, 16\r\n","    stage 1: 16x16, 32\r\n","    stage 2:  8x8,  64\r\n","    The Number of parameters is approx the same as Table 6 of [a]:\r\n","    ResNet20 0.27M\r\n","    ResNet32 0.46M\r\n","    ResNet44 0.66M\r\n","    ResNet56 0.85M\r\n","    ResNet110 1.7M\r\n","\r\n","    # Arguments\r\n","        input_shape (tensor): shape of input image tensor\r\n","        depth (int): number of core convolutional layers\r\n","        num_classes (int): number of classes (CIFAR10 has 10)\r\n","\r\n","    # Returns\r\n","        model (Model): keras model instance\r\n","    \"\"\"\r\n","    if (depth - 2) % 6 != 0:\r\n","        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\r\n","    # Start model definition.\r\n","    num_filters = 16\r\n","    num_res_blocks = int((depth - 2) / 6)\r\n","\r\n","    inputs = Input(shape=input_shape)\r\n","    x = resnet_layer(inputs=inputs)\r\n","    # Instantiate the stack of residual units\r\n","    for stack in range(3):\r\n","        for res_block in range(num_res_blocks):\r\n","            strides = 1\r\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n","                strides = 2  # downsample\r\n","            y = resnet_layer(inputs=x,\r\n","                             num_filters=num_filters,\r\n","                             strides=strides)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters,\r\n","                             activation=None)\r\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\r\n","                # linear projection residual shortcut connection to match\r\n","                # changed dims\r\n","                x = resnet_layer(inputs=x,\r\n","                                 num_filters=num_filters,\r\n","                                 kernel_size=1,\r\n","                                 strides=strides,\r\n","                                 activation=None,\r\n","                                 batch_normalization=False)\r\n","            x = keras.layers.add([x, y])\r\n","            x = Activation('relu')(x)\r\n","        num_filters *= 2\r\n","\r\n","    # Add classifier on top.\r\n","    # v1 does not use BN after last shortcut connection-ReLU\r\n","    x = AveragePooling2D(pool_size=8)(x)\r\n","    y = Flatten()(x)\r\n","    outputs = Dense(num_classes,\r\n","                    activation='softmax',\r\n","                    kernel_initializer='he_normal')(y)\r\n","\r\n","    # Instantiate model.\r\n","    model = Model(inputs=inputs, outputs=outputs)\r\n","    return model\r\n","\r\n","\r\n","def resnet_v2(input_shape, depth, num_classes=2):\r\n","    \"\"\"ResNet Version 2 Model builder [b]\r\n","\r\n","    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\r\n","    bottleneck layer\r\n","    First shortcut connection per layer is 1 x 1 Conv2D.\r\n","    Second and onwards shortcut connection is identity.\r\n","    At the beginning of each stage, the feature map size is halved (downsampled)\r\n","    by a convolutional layer with strides=2, while the number of filter maps is\r\n","    doubled. Within each stage, the layers have the same number filters and the\r\n","    same filter map sizes.\r\n","    Features maps sizes:\r\n","    conv1  : 32x32,  16\r\n","    stage 0: 32x32,  64\r\n","    stage 1: 16x16, 128\r\n","    stage 2:  8x8,  256\r\n","\r\n","    # Arguments\r\n","        input_shape (tensor): shape of input image tensor\r\n","        depth (int): number of core convolutional layers\r\n","        num_classes (int): number of classes (CIFAR10 has 10)\r\n","\r\n","    # Returns\r\n","        model (Model): keras model instance\r\n","    \"\"\"\r\n","    if (depth - 2) % 9 != 0:\r\n","        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\r\n","    # Start model definition.\r\n","    num_filters_in = 16\r\n","    num_res_blocks = int((depth - 2) / 9)\r\n","\r\n","    inputs = Input(shape=input_shape)\r\n","    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\r\n","    x = resnet_layer(inputs=inputs,\r\n","                     num_filters=num_filters_in,\r\n","                     conv_first=True)\r\n","\r\n","    # Instantiate the stack of residual units\r\n","    for stage in range(3):\r\n","        for res_block in range(num_res_blocks):\r\n","            activation = 'relu'\r\n","            batch_normalization = True\r\n","            strides = 1\r\n","            if stage == 0:\r\n","                num_filters_out = num_filters_in * 4\r\n","                if res_block == 0:  # first layer and first stage\r\n","                    activation = None\r\n","                    batch_normalization = False\r\n","            else:\r\n","                num_filters_out = num_filters_in * 2\r\n","                if res_block == 0:  # first layer but not first stage\r\n","                    strides = 2    # downsample\r\n","\r\n","            # bottleneck residual unit\r\n","            y = resnet_layer(inputs=x,\r\n","                             num_filters=num_filters_in,\r\n","                             kernel_size=1,\r\n","                             strides=strides,\r\n","                             activation=activation,\r\n","                             batch_normalization=batch_normalization,\r\n","                             conv_first=False)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters_in,\r\n","                             conv_first=False)\r\n","            y = resnet_layer(inputs=y,\r\n","                             num_filters=num_filters_out,\r\n","                             kernel_size=1,\r\n","                             conv_first=False)\r\n","            if res_block == 0:\r\n","                # linear projection residual shortcut connection to match\r\n","                # changed dims\r\n","                x = resnet_layer(inputs=x,\r\n","                                 num_filters=num_filters_out,\r\n","                                 kernel_size=1,\r\n","                                 strides=strides,\r\n","                                 activation=None,\r\n","                                 batch_normalization=False)\r\n","            x = keras.layers.add([x, y])\r\n","\r\n","        num_filters_in = num_filters_out\r\n","\r\n","    # Add classifier on top.\r\n","    # v2 has BN-ReLU before Pooling\r\n","    x = BatchNormalization()(x)\r\n","    x = Activation('relu')(x)\r\n","    x = AveragePooling2D(pool_size=8)(x)\r\n","    y = Flatten()(x)\r\n","    outputs = Dense(num_classes,\r\n","                    activation='softmax',\r\n","                    kernel_initializer='he_normal')(y)\r\n","\r\n","    # Instantiate model.\r\n","    model = Model(inputs=inputs, outputs=outputs)\r\n","    return model\r\n","\r\n","\r\n","if version == 2:\r\n","    model = resnet_v2(input_shape=(256,256,3), depth=depth,num_classes=2)\r\n","else:\r\n","    model = resnet_v1(input_shape=(256,256,3), depth=depth,num_classes=2)\r\n","\r\n","model.compile(loss='categorical_crossentropy',\r\n","              optimizer=Adam(lr=0.01),\r\n","              metrics=['accuracy'])\r\n","model.summary()\r\n","print(model_type)\r\n","\r\n","plot_model(model, show_shapes=True, to_file='/content/drive/My Drive/model_graph_resnet.png')\r\n","\r\n","# Prepare model model saving directory.\r\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\r\n","model_name = 'covid19_%s_model.{epoch:03d}.h5' % model_type\r\n","if not os.path.isdir(save_dir):\r\n","    os.makedirs(save_dir)\r\n","filepath = os.path.join(save_dir, model_name)\r\n","\r\n","# Prepare callbacks for model saving and for learning rate adjustment.\r\n","checkpoint = ModelCheckpoint(filepath=filepath,\r\n","                             monitor='val_acc',\r\n","                             verbose=1,\r\n","                             save_best_only=True)\r\n","\r\n","lr_scheduler = LearningRateScheduler(lr_schedule)\r\n","\r\n","lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\r\n","                               cooldown=0,\r\n","                               patience=5,\r\n","                               min_lr=0.5e-6)\r\n","\r\n","callbacks = [checkpoint, lr_reducer, lr_scheduler]\r\n","\r\n","# Run training, with or without data augmentation.\r\n","\r\n","# This will do preprocessing and realtime data augmentation:\r\n","datagen = ImageDataGenerator(\r\n","    rotation_range=40,\r\n","        width_shift_range=0.2,\r\n","        height_shift_range=0.2,\r\n","        rescale=1./255,\r\n","        shear_range=0.2,\r\n","        zoom_range=0.2,\r\n","        horizontal_flip=True,\r\n","        fill_mode='nearest'\r\n","    )\r\n","\r\n","# Compute quantities required for featurewise normalization\r\n","# (std, mean, and principal components if ZCA whitening is applied).\r\n","train_generator=datagen.flow_from_directory(directory='/content/drive/MyDrive/CT_COVID1.5',batch_size=64)\r\n","\r\n","# Fit the model on the batches generated by datagen.flow().\r\n","history = model.fit_generator(train_generator,\r\n","                    epochs=10,\r\n","                    callbacks=callbacks)\r\n","model.save(\"/content/drive/My Drive/covidResnet15_epoch10.h5\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"model_4\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_5 (InputLayer)            [(None, 256, 256, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_84 (Conv2D)              (None, 256, 256, 16) 448         input_5[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_76 (BatchNo (None, 256, 256, 16) 64          conv2d_84[0][0]                  \n","__________________________________________________________________________________________________\n","activation_76 (Activation)      (None, 256, 256, 16) 0           batch_normalization_76[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_85 (Conv2D)              (None, 256, 256, 16) 2320        activation_76[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_77 (BatchNo (None, 256, 256, 16) 64          conv2d_85[0][0]                  \n","__________________________________________________________________________________________________\n","activation_77 (Activation)      (None, 256, 256, 16) 0           batch_normalization_77[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_86 (Conv2D)              (None, 256, 256, 16) 2320        activation_77[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_78 (BatchNo (None, 256, 256, 16) 64          conv2d_86[0][0]                  \n","__________________________________________________________________________________________________\n","add_36 (Add)                    (None, 256, 256, 16) 0           activation_76[0][0]              \n","                                                                 batch_normalization_78[0][0]     \n","__________________________________________________________________________________________________\n","activation_78 (Activation)      (None, 256, 256, 16) 0           add_36[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_87 (Conv2D)              (None, 256, 256, 16) 2320        activation_78[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 256, 256, 16) 64          conv2d_87[0][0]                  \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 256, 256, 16) 0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 256, 256, 16) 2320        activation_79[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 256, 256, 16) 64          conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","add_37 (Add)                    (None, 256, 256, 16) 0           activation_78[0][0]              \n","                                                                 batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 256, 256, 16) 0           add_37[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 256, 256, 16) 2320        activation_80[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 256, 256, 16) 64          conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 256, 256, 16) 0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 256, 256, 16) 2320        activation_81[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 256, 256, 16) 64          conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","add_38 (Add)                    (None, 256, 256, 16) 0           activation_80[0][0]              \n","                                                                 batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 256, 256, 16) 0           add_38[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 128, 128, 32) 4640        activation_82[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 128, 128, 32) 128         conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 128, 128, 32) 0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 128, 128, 32) 9248        activation_83[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 128, 128, 32) 544         activation_82[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 128, 128, 32) 128         conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","add_39 (Add)                    (None, 128, 128, 32) 0           conv2d_93[0][0]                  \n","                                                                 batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 128, 128, 32) 0           add_39[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 128, 128, 32) 9248        activation_84[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 128, 128, 32) 128         conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 128, 128, 32) 0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 128, 128, 32) 9248        activation_85[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 128, 128, 32) 128         conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","add_40 (Add)                    (None, 128, 128, 32) 0           activation_84[0][0]              \n","                                                                 batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 128, 128, 32) 0           add_40[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 128, 128, 32) 9248        activation_86[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 128, 128, 32) 128         conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 128, 128, 32) 0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 128, 128, 32) 9248        activation_87[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 128, 128, 32) 128         conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","add_41 (Add)                    (None, 128, 128, 32) 0           activation_86[0][0]              \n","                                                                 batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 128, 128, 32) 0           add_41[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 64, 64, 64)   18496       activation_88[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 64, 64, 64)   256         conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 64, 64, 64)   0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 64, 64, 64)   36928       activation_89[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 64, 64, 64)   2112        activation_88[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 64, 64, 64)   256         conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","add_42 (Add)                    (None, 64, 64, 64)   0           conv2d_100[0][0]                 \n","                                                                 batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 64, 64, 64)   0           add_42[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 64, 64, 64)   36928       activation_90[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 64, 64, 64)   256         conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 64, 64, 64)   0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 64, 64, 64)   36928       activation_91[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 64, 64, 64)   256         conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","add_43 (Add)                    (None, 64, 64, 64)   0           activation_90[0][0]              \n","                                                                 batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 64, 64, 64)   0           add_43[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 64, 64, 64)   36928       activation_92[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 64, 64, 64)   256         conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 64, 64, 64)   0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 64, 64, 64)   36928       activation_93[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 64, 64, 64)   256         conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","add_44 (Add)                    (None, 64, 64, 64)   0           activation_92[0][0]              \n","                                                                 batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 64, 64, 64)   0           add_44[0][0]                     \n","__________________________________________________________________________________________________\n","average_pooling2d_4 (AveragePoo (None, 8, 8, 64)     0           activation_94[0][0]              \n","__________________________________________________________________________________________________\n","flatten_4 (Flatten)             (None, 4096)         0           average_pooling2d_4[0][0]        \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 2)            8194        flatten_4[0][0]                  \n","==================================================================================================\n","Total params: 281,986\n","Trainable params: 280,610\n","Non-trainable params: 1,376\n","__________________________________________________________________________________________________\n","ResNet20v1\n","Found 1677 images belonging to 2 classes.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","Learning rate:  0.001\n","27/27 [==============================] - 759s 28s/step - loss: 1.8903 - accuracy: 0.6666\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 2/10\n","Learning rate:  0.001\n","27/27 [==============================] - 37s 1s/step - loss: 0.6270 - accuracy: 0.7750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 3/10\n","Learning rate:  0.001\n","27/27 [==============================] - 37s 1s/step - loss: 0.5562 - accuracy: 0.8073\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 4/10\n","Learning rate:  0.001\n","27/27 [==============================] - 37s 1s/step - loss: 0.5683 - accuracy: 0.8118\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 5/10\n","Learning rate:  0.001\n","27/27 [==============================] - 37s 1s/step - loss: 0.5988 - accuracy: 0.7813\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 6/10\n","Learning rate:  0.001\n","27/27 [==============================] - 37s 1s/step - loss: 0.5731 - accuracy: 0.7988\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 7/10\n","Learning rate:  0.001\n","27/27 [==============================] - 38s 1s/step - loss: 0.5049 - accuracy: 0.8290\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 8/10\n","Learning rate:  0.001\n","27/27 [==============================] - 37s 1s/step - loss: 0.5053 - accuracy: 0.8340\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 9/10\n","Learning rate:  0.001\n","27/27 [==============================] - 38s 1s/step - loss: 0.5268 - accuracy: 0.8304\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n","Epoch 10/10\n","Learning rate:  0.001\n","27/27 [==============================] - 38s 1s/step - loss: 0.4978 - accuracy: 0.8610\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"],"name":"stdout"}]}]}